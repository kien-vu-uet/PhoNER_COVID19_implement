{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/nlplab/kienvt/PhoNER_COVID19_implement/nerenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "\n",
    "# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
    "sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "## With TensorFlow 2.0+:\n",
    "# from transformers import TFAutoModel\n",
    "# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2316, 790, 4, 326, 2142, 917, 9170, 2927, 380, 9, 19289, 6222, 292, 335, 1626, 326, 3, 31, 1195, 63, 455, 376, 7, 125, 2406, 7564, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "text = 'Đồng thời , bệnh viện tiếp tục thực hiện các biện pháp phòng chống dịch bệnh COVID - 19 theo hướng dẫn của Bộ Y tế .'\n",
    "\n",
    "enc = tokenizer.encode(text.split(), add_special_tokens=False)\n",
    "enc.insert(0, tokenizer.cls_token_id)\n",
    "enc.append(tokenizer.sep_token_id)\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phobert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Chúng_tôi là những nghiên_cứu_viên. </s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(id) for id in [tokenizer.encode(sentence)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.pooler_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 4, 1: 3, 3: 3})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt = Counter([1, 2, 3, 1, 2, 3, 3, 2, 1, 2])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open('../data/syllable/train_syllable.json', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5027"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_in_length = []\n",
    "\n",
    "for item in data:\n",
    "    sentence_in_length.append(len(item['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sentence: 186\n",
      "Avarage length of sentence: 33\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of sentence:\", max(sentence_in_length))\n",
    "print(\"Avarage length of sentence:\", sum(sentence_in_length) // len(sentence_in_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover rate of sentence which has length <= 100: 0.9976128903918838\n"
     ]
    }
   ],
   "source": [
    "print(\"Cover rate of sentence which has length <= 100:\", len([p for p in sentence_in_length if p <= 100]) / len(sentence_in_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Đồng thời , bệnh viện tiếp tục thực hiện các biện pháp phòng chống dịch bệnh COVID - 19 theo hướng dẫn của Bộ Y tế .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = data[0]['words']\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2316, 790, 4, 326, 2142, 917, 9170, 2927, 380, 9, 19289, 6222, 292, 335, 1626, 326, 3, 31, 1195, 63, 455, 376, 7, 125, 2406, 7564, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(words, add_special_tokens=False, max_length=100, padding='max_length', truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2316, 790, 4, 326, 2142, 917, 9170, 2927, 380, 9, 19289, 6222, 292, 335, 1626, 326, 3, 31, 1195, 63, 455, 376, 7, 125, 2406, 7564, 5]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(tokenizer, words):\n",
    "    results = []\n",
    "    for w in words:\n",
    "        token = tokenizer.encode(w)[1:-1]\n",
    "        results.append(tokenizer.unk_token_id if len(token) > 1 else token[0])\n",
    "    return results\n",
    "\n",
    "print(tokenize(tokenizer, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenize(tokenizer, words)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "features.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "for idx in input_ids[0]:\n",
    "    print(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt = Counter([1, 2, 3, 4, 3, 2, 3, 2, 1])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "cnt.update([1, 5, 2, 4])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "cnt = Counter([])\n",
    "\n",
    "for item in data:\n",
    "    try:\n",
    "        cnt.update(item['tags'])\n",
    "    except Exception:\n",
    "        print('exception')\n",
    "        print(item)\n",
    "\n",
    "len(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ORGANIZATION': 1,\n",
       " 'I-ORGANIZATION': 2,\n",
       " 'B-SYMPTOM_AND_DISEASE': 3,\n",
       " 'I-SYMPTOM_AND_DISEASE': 4,\n",
       " 'B-LOCATION': 5,\n",
       " 'I-LOCATION': 6,\n",
       " 'B-PATIENT_ID': 7,\n",
       " 'I-PATIENT_ID': 8,\n",
       " 'B-DATE': 9,\n",
       " 'I-DATE': 10,\n",
       " 'B-AGE': 11,\n",
       " 'I-AGE': 12,\n",
       " 'B-NAME': 13,\n",
       " 'I-NAME': 14,\n",
       " 'B-JOB': 15,\n",
       " 'I-JOB': 16,\n",
       " 'B-TRANSPORTATION': 17,\n",
       " 'I-TRANSPORTATION': 18,\n",
       " 'B-GENDER': 19,\n",
       " 'I-GENDER': 20}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'O': 0,\n",
    "    'B-ORGANIZATION': 1,\n",
    "    'I-ORGANIZATION': 2,\n",
    "    'B-SYMPTOM_AND_DISEASE': 3,\n",
    "    'I-SYMPTOM_AND_DISEASE': 4,\n",
    "    'B-LOCATION': 5,\n",
    "    'I-LOCATION': 6,\n",
    "    'B-PATIENT_ID': 7,\n",
    "    'I-PATIENT_ID': 8,\n",
    "    'B-DATE': 9,\n",
    "    'I-DATE': 10,\n",
    "    'B-AGE': 11,\n",
    "    'I-AGE': 12,\n",
    "    'B-NAME': 13,\n",
    "    'I-NAME': 14,\n",
    "    'B-JOB': 15,\n",
    "    'I-JOB': 16,\n",
    "    'B-TRANSPORTATION': 17,\n",
    "    'I-TRANSPORTATION': 18,\n",
    "    'B-GENDER': 19,\n",
    "    'I-GENDER': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39msorted\u001b[39m(cnt\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnt' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nerenv' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# a = torch.randint(0, 10, size=(3, 10))\n",
    "b = torch.softmax(torch.randn(size=(3, 10, 5)), dim = -1)\n",
    "b.view(-1).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
