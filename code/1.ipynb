{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/nlplab/kienvt/PhoNER_COVID19/nerenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "\n",
    "# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
    "sentence = 'Chúng_tôi là những nghiên_cứu_viên .'  \n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "## With TensorFlow 2.0+:\n",
    "# from transformers import TFAutoModel\n",
    "# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2316,\n",
       " 790,\n",
       " 4,\n",
       " 326,\n",
       " 2142,\n",
       " 917,\n",
       " 9170,\n",
       " 2927,\n",
       " 380,\n",
       " 9,\n",
       " 19289,\n",
       " 6222,\n",
       " 292,\n",
       " 335,\n",
       " 1626,\n",
       " 326,\n",
       " 3,\n",
       " 31,\n",
       " 1195,\n",
       " 63,\n",
       " 455,\n",
       " 376,\n",
       " 7,\n",
       " 125,\n",
       " 2406,\n",
       " 7564,\n",
       " 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Đồng thời , bệnh viện tiếp tục thực hiện các biện pháp phòng chống dịch bệnh COVID - 19 theo hướng dẫn của Bộ Y tế .'\n",
    "\n",
    "tokenizer.encode(text.split(), add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phobert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Chúng tôi là những nghiên cứu viên. </s>']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(id) for id in [tokenizer.encode(sentence)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.pooler_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 4, 3: 3})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt = Counter([1, 2, 3, 1, 2, 3, 3, 2, 1, 2])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open('../data/syllable/train_syllable.json', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5027"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_in_length = []\n",
    "\n",
    "for item in data:\n",
    "    sentence_in_length.append(len(item['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sentence: 186\n",
      "Avarage length of sentence: 33\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of sentence:\", max(sentence_in_length))\n",
    "print(\"Avarage length of sentence:\", sum(sentence_in_length) // len(sentence_in_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover rate of sentence which has length <= 100: 0.9976128903918838\n"
     ]
    }
   ],
   "source": [
    "print(\"Cover rate of sentence which has length <= 100:\", len([p for p in sentence_in_length if p <= 100]) / len(sentence_in_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Đồng thời , bệnh viện tiếp tục thực hiện các biện pháp phòng chống dịch bệnh COVID - 19 theo hướng dẫn của Bộ Y tế .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = data[0]['words']\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2316, 790, 4, 326, 2142, 917, 9170, 2927, 380, 9, 19289, 6222, 292, 335, 1626, 326, 3, 31, 1195, 63, 455, 376, 7, 125, 2406, 7564, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(words, add_special_tokens=False, max_length=100, padding='max_length', truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2316, 790, 4, 326, 2142, 917, 9170, 2927, 380, 9, 19289, 6222, 292, 335, 1626, 326, 3, 31, 1195, 63, 455, 376, 7, 125, 2406, 7564, 5]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(tokenizer, words):\n",
    "    results = []\n",
    "    for w in words:\n",
    "        token = tokenizer.encode(w)[1:-1]\n",
    "        results.append(tokenizer.unk_token_id if len(token) > 1 else token[0])\n",
    "    return results\n",
    "\n",
    "print(tokenize(tokenizer, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27, 768])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenize(tokenizer, words)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "features.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  2460,    70,     8,    21, 25925,  1098,  1430,     5,     2]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< s >\n",
      "đ ồ n g\n",
      "t h ờ i\n",
      ",\n",
      "b ệ n h\n",
      "v i ệ n\n",
      "t i ế p\n",
      "t ụ c\n",
      "t h ự c\n",
      "h i ệ n\n",
      "c á c\n",
      "b i ệ n\n",
      "p h á p\n",
      "p h ò n g\n",
      "c h ố n g\n",
      "d ị c h\n",
      "b ệ n h\n",
      "c o @ @\n",
      "v i @ @\n",
      "d\n",
      "-\n",
      "1 9\n",
      "t h e o\n",
      "h ư ớ n g\n",
      "d ẫ n\n",
      "c ủ a\n",
      "b ộ\n",
      "y\n",
      "t ế\n",
      ".\n",
      "< / s >\n"
     ]
    }
   ],
   "source": [
    "for idx in input_ids[0]:\n",
    "    print(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 3, 3: 3, 4: 1})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt = Counter([1, 2, 3, 4, 3, 2, 3, 2, 1])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 4, 3: 3, 4: 2, 5: 1})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.update([1, 5, 2, 4])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter([])\n",
    "\n",
    "for item in data:\n",
    "    try:\n",
    "        cnt.update(item['tags'])\n",
    "    except Exception:\n",
    "        print('exception')\n",
    "        print(item)\n",
    "\n",
    "len(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 129379,\n",
       "         'B-ORGANIZATION': 1137,\n",
       "         'I-ORGANIZATION': 4818,\n",
       "         'B-SYMPTOM_AND_DISEASE': 1439,\n",
       "         'I-SYMPTOM_AND_DISEASE': 2270,\n",
       "         'B-LOCATION': 5398,\n",
       "         'I-LOCATION': 12309,\n",
       "         'B-DATE': 2549,\n",
       "         'B-PATIENT_ID': 3240,\n",
       "         'B-AGE': 682,\n",
       "         'B-NAME': 349,\n",
       "         'I-DATE': 2500,\n",
       "         'B-JOB': 205,\n",
       "         'I-JOB': 318,\n",
       "         'B-TRANSPORTATION': 226,\n",
       "         'B-GENDER': 542,\n",
       "         'I-GENDER': 14,\n",
       "         'I-TRANSPORTATION': 69,\n",
       "         'I-NAME': 80,\n",
       "         'I-AGE': 2,\n",
       "         'I-PATIENT_ID': 15})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'O': 0,\n",
    "    'B-ORGANIZATION': 1,\n",
    "    'I-ORGANIZATION': 2,\n",
    "    'B-SYMPTOM_AND_DISEASE': 3,\n",
    "    'I-SYMPTOM_AND_DISEASE': 4,\n",
    "    'B-LOCATION': 5,\n",
    "    'I-LOCATION': 6,\n",
    "    'B-PATIENT_ID': 7,\n",
    "    'I-PATIENT_ID': 8,\n",
    "    'B-DATE': 9,\n",
    "    'I-DATE': 10,\n",
    "    'B-AGE': 11,\n",
    "    'I-AGE': 12,\n",
    "    'B-NAME': 13,\n",
    "    'I-NAME': 14,\n",
    "    'B-JOB': 15,\n",
    "    'I-JOB': 16,\n",
    "    'B-TRANSPORTATION': 17,\n",
    "    'I-TRANSPORTATION': 18,\n",
    "    'B-GENDER': 19,\n",
    "    'I-GENDER': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-AGE',\n",
       " 'B-DATE',\n",
       " 'B-GENDER',\n",
       " 'B-JOB',\n",
       " 'B-LOCATION',\n",
       " 'B-NAME',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-PATIENT_ID',\n",
       " 'B-SYMPTOM_AND_DISEASE',\n",
       " 'B-TRANSPORTATION',\n",
       " 'I-AGE',\n",
       " 'I-DATE',\n",
       " 'I-GENDER',\n",
       " 'I-JOB',\n",
       " 'I-LOCATION',\n",
       " 'I-NAME',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-PATIENT_ID',\n",
       " 'I-SYMPTOM_AND_DISEASE',\n",
       " 'I-TRANSPORTATION',\n",
       " 'O']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False,  True, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# a = torch.randint(0, 10, size=(3, 10))\n",
    "b = torch.softmax(torch.randn(size=(3, 10, 5)), dim = -1)\n",
    "b.view(-1).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
